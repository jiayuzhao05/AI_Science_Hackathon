{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3952e9f6-751e-4180-91e7-df4f94107ba3",
   "metadata": {},
   "source": [
    "This jupyter notebook teaches you how to create a dynamic (i.e. trained) state reduction object and how to train and use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92edcf65-93c1-4396-90d0-4572ec09c2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "# Add parent directory to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "current_dir = Path().resolve()\n",
    "root_dir = current_dir.parent\n",
    "if str(root_dir) not in sys.path:\n",
    "    sys.path.insert(0,str(root_dir))\n",
    "\n",
    "from Gyms.SimulatedNetwork import SimulatedNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7a528d5-af3f-4c5b-9bef-0fe0022a21cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the state reduction function\n",
    "from StateReduction.DynamicStatePCA import DynamicStatePCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5373dba-d31c-4f31-9906-6db506053bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define size of state and action spaces\n",
    "state_dim  = 4 # Dimension of reduced state space\n",
    "action_dim = 5 # Number of stimuli in action space (each stimulus needs a value of {0,1,2,3,4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dc3ef6a-fb75-4834-b6e0-97826997584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object of the state reduction function\n",
    "state = DynamicStatePCA(state_dim=state_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72e153a0-a5c9-4873-950b-26cf395f3189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state: [0. 0. 0. 0.], Reward: 0\n"
     ]
    }
   ],
   "source": [
    "# Create environment and initialize it\n",
    "env      = SimulatedNetwork(action_dim=action_dim,\n",
    "                            state_dim=state_dim,\n",
    "                            state_object=state) # Use the state object\n",
    "state, _ = env.reset()\n",
    "env.render() # This function gives you the current state + reward, which both is 0 after initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3224ae1-8590-4fa6-99e3-ca65ce51e42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 1000 responses to random stimuli for training\n",
    "spikes    = []\n",
    "elecs     = []\n",
    "for i in range(1000):\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    \n",
    "    spikes.append(info['spikes'])\n",
    "    elecs.append(info['elecs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8164cc17-2264-405e-90c2-d80ad74c0199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your state function (Notice, you are doing this through your environment)\n",
    "env.fit(spikes,elecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e01d04d-21a2-4760-9f81-7bfe2884a916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stimulate with action: [3 2 1 3 2]\n",
      "Reward: 1, Avg. reward: 1.0\n",
      "State: [[ 0.54678344 -0.44760533 -0.34995769 -0.40822793]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0 1 3 4]\n",
      "Reward: 2, Avg. reward: 1.5\n",
      "State: [[-0.27339561  0.03030624 -0.32796041  0.18190155]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3 2 4 4]\n",
      "Reward: -1, Avg. reward: 0.6666666666666666\n",
      "State: [[-0.51084699 -0.82450463 -0.46722565 -0.38053875]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1 2 4 4]\n",
      "Reward: -1, Avg. reward: 0.25\n",
      "State: [[ 0.02326778 -0.31836617 -0.59891569 -0.2656341 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1 4 0 3]\n",
      "Reward: 2, Avg. reward: 0.6\n",
      "State: [[-0.04442075 -0.10680551 -0.26027669 -0.13704047]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4 4 4 2]\n",
      "Reward: 2, Avg. reward: 0.8333333333333334\n",
      "State: [[-0.43085258  0.24221989  0.58527482 -0.17081639]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 1 3 2 3]\n",
      "Reward: 1, Avg. reward: 0.8571428571428571\n",
      "State: [[ 0.06311868  0.07138077 -0.3310507  -0.08731435]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3 1 1 2]\n",
      "Reward: 1, Avg. reward: 0.875\n",
      "State: [[-0.60647033  0.05627591  0.09835913 -0.20840273]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0 1 0 1]\n",
      "Reward: 1, Avg. reward: 0.8888888888888888\n",
      "State: [[-0.36953345  0.40294981  0.07523528  0.12060533]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2 2 2 3]\n",
      "Reward: 2, Avg. reward: 1.0\n",
      "State: [[-0.01387556 -0.12961912 -0.33188876 -1.04849831]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2 0 4 3]\n",
      "Reward: 0, Avg. reward: 0.9090909090909091\n",
      "State: [[ 0.19211294 -0.18574072 -0.4680804  -0.13277301]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0 2 0 1]\n",
      "Reward: 2, Avg. reward: 1.0\n",
      "State: [[-0.39221056 -0.11265927  0.11073167 -0.24571859]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 0 1 1 1]\n",
      "Reward: 3, Avg. reward: 1.1538461538461537\n",
      "State: [[-0.52372144 -0.02346227  0.31812953 -0.36461843]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4 4 4 4]\n",
      "Reward: 1, Avg. reward: 1.1428571428571428\n",
      "State: [[-0.15413242  0.09486514 -0.39966609 -0.60537638]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0 3 4 3]\n",
      "Reward: 4, Avg. reward: 1.3333333333333333\n",
      "State: [[-0.19386578  0.03878013 -0.18150964 -0.32012447]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 1 1 2 0]\n",
      "Reward: 2, Avg. reward: 1.375\n",
      "State: [[ 0.04063864  0.24599502 -0.13947456 -0.13531286]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2 1 1 2]\n",
      "Reward: 1, Avg. reward: 1.3529411764705883\n",
      "State: [[-4.01080760e-04 -4.35077756e-01  1.25796322e-01  6.78479875e-02]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3 3 0 4]\n",
      "Reward: 2, Avg. reward: 1.3888888888888888\n",
      "State: [[-0.30865386 -0.5832345   0.00344002 -0.01354228]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1 2 0 4]\n",
      "Reward: 1, Avg. reward: 1.368421052631579\n",
      "State: [[-0.02131654 -0.1236715  -0.26467305 -0.22015082]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4 4 4 2]\n",
      "Reward: -5, Avg. reward: 1.05\n",
      "State: [[-0.63431624  0.15666897 -0.17647995 -0.16816158]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4 4 1 3]\n",
      "Reward: 0, Avg. reward: 1.0\n",
      "State: [[ 0.2767527  -0.38852989 -0.20245679 -0.53016117]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4 0 3 1]\n",
      "Reward: 2, Avg. reward: 1.0454545454545454\n",
      "State: [[-0.15714976 -0.06669741  0.14925123 -0.66267056]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2 2 1 1]\n",
      "Reward: 0, Avg. reward: 1.0\n",
      "State: [[-0.37157318  0.35262538 -0.08656759 -0.24900545]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0 2 1 3]\n",
      "Reward: -2, Avg. reward: 0.875\n",
      "State: [[-0.05069774 -0.01353596  0.00116598 -0.69291164]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1 0 2 3]\n",
      "Reward: 5, Avg. reward: 1.04\n",
      "State: [[-0.16492717 -0.1573318  -0.77142448 -0.54431516]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 3 3 2 3]\n",
      "Reward: 3, Avg. reward: 1.1153846153846154\n",
      "State: [[-0.12059092 -0.41898995 -0.93407245  0.19308339]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2 2 4 3]\n",
      "Reward: -3, Avg. reward: 0.9629629629629629\n",
      "State: [[-0.1239214  -0.70534837 -1.11694725 -0.00352463]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3 2 0 3]\n",
      "Reward: 1, Avg. reward: 0.9642857142857143\n",
      "State: [[-0.28692582  0.05991363 -0.32870574 -0.05250139]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4 0 2 3]\n",
      "Reward: 4, Avg. reward: 1.0689655172413792\n",
      "State: [[-0.14075106  0.00437727 -0.56991294 -0.64032969]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 3 3 0 3]\n",
      "Reward: 1, Avg. reward: 1.0666666666666667\n",
      "State: [[ 0.08613199  0.44606159 -0.90197091 -0.42272313]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0 0 2 3]\n",
      "Reward: 3, Avg. reward: 1.1290322580645162\n",
      "State: [[-0.01080075  0.04621721 -0.59668418 -0.1394772 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4 2 0 2]\n",
      "Reward: -2, Avg. reward: 1.03125\n",
      "State: [[-0.14158292  0.27905163  0.15676285 -0.42032799]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3 3 4 1]\n",
      "Reward: 3, Avg. reward: 1.0909090909090908\n",
      "State: [[-0.20475511  0.02495749 -0.53025358 -0.32284013]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2 3 3 2]\n",
      "Reward: -1, Avg. reward: 1.0294117647058822\n",
      "State: [[-0.38989328 -0.26435443 -0.60346483 -0.27719707]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1 0 3 4]\n",
      "Reward: 4, Avg. reward: 1.1142857142857143\n",
      "State: [[ 0.08614169 -0.42300348  0.01163025 -0.32882149]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 3 1 3 0]\n",
      "Reward: 3, Avg. reward: 1.1666666666666667\n",
      "State: [[-0.46282737  0.73208629 -0.33482229 -0.51376462]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1 0 2 0]\n",
      "Reward: 3, Avg. reward: 1.2162162162162162\n",
      "State: [[-0.01024071 -0.01910988  0.17943352 -0.15452878]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3 0 3 1]\n",
      "Reward: 3, Avg. reward: 1.263157894736842\n",
      "State: [[-0.59567447  0.06069478 -0.1058816  -0.55647028]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0 4 2 0]\n",
      "Reward: 4, Avg. reward: 1.3333333333333333\n",
      "State: [[-0.19774528  0.21535912  0.24539045 -0.36933053]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3 2 1 3]\n",
      "Reward: -1, Avg. reward: 1.275\n",
      "State: [[-0.05498007 -0.21347634 -0.04792391 -0.11592332]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2 4 1 4]\n",
      "Reward: -1, Avg. reward: 1.2195121951219512\n",
      "State: [[-0.37632773 -0.09060025 -0.0453141  -0.77397936]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1 2 2 2]\n",
      "Reward: 1, Avg. reward: 1.2142857142857142\n",
      "State: [[-0.06170785 -0.02347946 -0.03843602 -0.02911673]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0 3 4 3]\n",
      "Reward: 4, Avg. reward: 1.2790697674418605\n",
      "State: [[ 0.28822149 -0.32240082 -0.77895075 -0.37630177]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3 4 0 1]\n",
      "Reward: 3, Avg. reward: 1.3181818181818181\n",
      "State: [[-0.397338   -0.22048984  0.00540163 -0.57316139]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1 4 1 4]\n",
      "Reward: 4, Avg. reward: 1.3777777777777778\n",
      "State: [[ 0.39674475  0.30195154 -0.12848955 -0.44174336]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 3 2 3 0]\n",
      "Reward: 2, Avg. reward: 1.391304347826087\n",
      "State: [[-0.09892094  0.02779668  0.04949386  0.28927795]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4 4 1 0]\n",
      "Reward: 2, Avg. reward: 1.4042553191489362\n",
      "State: [[-0.54299341  0.06020275  0.12167341 -0.28968608]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 3 0 3 0]\n",
      "Reward: 1, Avg. reward: 1.3958333333333333\n",
      "State: [[-0.27855022 -0.02031833 -0.20394679 -0.0803303 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2 4 2 3]\n",
      "Reward: 2, Avg. reward: 1.4081632653061225\n",
      "State: [[-0.20221931 -0.12123927 -0.43493132 -0.6119894 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 1 1 2 1]\n",
      "Reward: 3, Avg. reward: 1.44\n",
      "State: [[-0.2508753  -0.33784087 -0.10834478 -0.53266056]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0 1 3 1]\n",
      "Reward: -1, Avg. reward: 1.392156862745098\n",
      "State: [[-0.24972717 -0.24853278 -0.02170722 -0.27158942]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4 2 1 0]\n",
      "Reward: -1, Avg. reward: 1.3461538461538463\n",
      "State: [[-0.24343837  0.43193157 -0.43477993 -0.59202754]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2 0 0 3]\n",
      "Reward: 0, Avg. reward: 1.320754716981132\n",
      "State: [[ 0.26985635 -0.25487969  0.04061841 -0.00955449]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0 1 2 3]\n",
      "Reward: 3, Avg. reward: 1.3518518518518519\n",
      "State: [[-0.26518918  0.60409376 -0.17417976 -0.35506491]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4 3 2 0]\n",
      "Reward: -3, Avg. reward: 1.2727272727272727\n",
      "State: [[ 0.0535061  -0.28444039  0.03012292 -0.22723416]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0 1 1 1]\n",
      "Reward: 0, Avg. reward: 1.25\n",
      "State: [[-0.1479146  -0.17326652 -0.16773693 -0.21694521]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4 3 3 0]\n",
      "Reward: -2, Avg. reward: 1.1929824561403508\n",
      "State: [[-0.57715753  0.16857895 -0.2215264  -0.69956713]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 3 2 2 4]\n",
      "Reward: 4, Avg. reward: 1.2413793103448276\n",
      "State: [[-0.29463417 -0.58791014 -0.5582955  -1.0138733 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4 4 0 3]\n",
      "Reward: 2, Avg. reward: 1.2542372881355932\n",
      "State: [[ 0.15278353  0.02601323 -0.19131919 -0.41354912]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3 0 0 2]\n",
      "Reward: 0, Avg. reward: 1.2333333333333334\n",
      "State: [[-0.12950864 -0.24300107  0.01457288 -0.02067918]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0 1 4 3]\n",
      "Reward: 2, Avg. reward: 1.2459016393442623\n",
      "State: [[ 0.16524069 -0.25452111 -0.12823715 -0.64345784]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4 0 4 2]\n",
      "Reward: -1, Avg. reward: 1.2096774193548387\n",
      "State: [[-0.30684192  0.13199862  0.02160939 -0.05223206]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3 3 1 3]\n",
      "Reward: 0, Avg. reward: 1.1904761904761905\n",
      "State: [[-0.6627711  -0.22338603 -0.62128916 -0.05710308]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4 0 4 2]\n",
      "Reward: 4, Avg. reward: 1.234375\n",
      "State: [[ 0.40318752  0.0531993  -0.40622515 -0.35639839]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 2 4 1 2]\n",
      "Reward: 1, Avg. reward: 1.2307692307692308\n",
      "State: [[-0.5743307  -0.2503967   0.09208228 -0.18422553]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1 4 1 1]\n",
      "Reward: 0, Avg. reward: 1.2121212121212122\n",
      "State: [[-0.19979197 -0.30446194  0.51710142 -0.37600324]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0 2 0 0]\n",
      "Reward: 1, Avg. reward: 1.208955223880597\n",
      "State: [[-0.15746048 -0.13961698 -0.20809823  0.32531518]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1 1 1 1]\n",
      "Reward: 1, Avg. reward: 1.2058823529411764\n",
      "State: [[ 0.08726786  0.9301283  -0.17231294 -0.22958503]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4 0 1 1]\n",
      "Reward: 3, Avg. reward: 1.2318840579710144\n",
      "State: [[-0.44997221  0.13875568  0.12722537 -0.47009383]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4 2 1 0]\n",
      "Reward: 1, Avg. reward: 1.2285714285714286\n",
      "State: [[-0.45382792  0.15445626 -0.05774493 -0.2215405 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3 1 4 2]\n",
      "Reward: 3, Avg. reward: 1.2535211267605635\n",
      "State: [[-0.42255869 -0.11439396 -0.07855314  0.21575493]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4 1 0 0]\n",
      "Reward: 3, Avg. reward: 1.2777777777777777\n",
      "State: [[ 0.08100437 -0.13006822  0.06478898 -0.80843871]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3 0 3 0]\n",
      "Reward: 1, Avg. reward: 1.273972602739726\n",
      "State: [[-0.27422759  0.1311931  -0.34363692 -0.3200379 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0 0 2 0]\n",
      "Reward: 1, Avg. reward: 1.2702702702702702\n",
      "State: [[-0.04878322 -0.20085192 -0.15380517 -0.13356748]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4 0 0 2]\n",
      "Reward: 1, Avg. reward: 1.2666666666666666\n",
      "State: [[-0.33584633  0.10729995  0.06872054 -0.40594651]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0 2 4 3]\n",
      "Reward: -1, Avg. reward: 1.236842105263158\n",
      "State: [[ 0.20017177 -0.10723644 -0.01786724 -0.37030824]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4 4 1 2]\n",
      "Reward: 5, Avg. reward: 1.2857142857142858\n",
      "State: [[-0.33231205  0.21417406  0.15374849 -0.5890195 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 2 0 1 2]\n",
      "Reward: 2, Avg. reward: 1.294871794871795\n",
      "State: [[-0.42320021 -0.0226823  -0.17504255 -0.51594511]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3 3 4 3]\n",
      "Reward: 0, Avg. reward: 1.2784810126582278\n",
      "State: [[-0.12227416 -0.35390161 -0.32556579 -0.36781644]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4 1 1 4]\n",
      "Reward: 4, Avg. reward: 1.3125\n",
      "State: [[-0.55471408 -0.13887068  0.15327766 -0.1469483 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3 3 3 0]\n",
      "Reward: 1, Avg. reward: 1.308641975308642\n",
      "State: [[-0.21549386  0.22248573 -0.39510025 -0.5377943 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 0 1 3 3]\n",
      "Reward: 2, Avg. reward: 1.3170731707317074\n",
      "State: [[ 0.44410373 -0.05851452 -0.35678106 -0.5968368 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0 4 2 1]\n",
      "Reward: -1, Avg. reward: 1.2891566265060241\n",
      "State: [[-0.56436599 -0.0362192   0.24971839 -0.7116401 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4 4 4 2]\n",
      "Reward: 3, Avg. reward: 1.3095238095238095\n",
      "State: [[-0.76723412  0.09652457 -0.1232237   0.14026158]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4 3 1 0]\n",
      "Reward: 0, Avg. reward: 1.2941176470588236\n",
      "State: [[-0.16026307 -0.34790059  0.08714917 -0.04706937]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4 0 4 0]\n",
      "Reward: 0, Avg. reward: 1.2790697674418605\n",
      "State: [[-0.13253038 -0.03807267  0.27377234 -0.0047852 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0 4 3 0]\n",
      "Reward: -2, Avg. reward: 1.2413793103448276\n",
      "State: [[ 0.13593304 -0.37319681  0.05358473  0.06295205]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3 0 2 1]\n",
      "Reward: 1, Avg. reward: 1.2386363636363635\n",
      "State: [[-0.29021237 -0.30787106  0.11899839 -0.68660952]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0 1 1 0]\n",
      "Reward: -2, Avg. reward: 1.202247191011236\n",
      "State: [[-0.1085253  -0.01121259 -0.12253038  0.34492708]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3 4 4 2]\n",
      "Reward: 3, Avg. reward: 1.2222222222222223\n",
      "State: [[-2.18969414e-01 -1.64804681e-01 -9.70538283e-05 -4.82657531e-01]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4 2 4 3]\n",
      "Reward: 2, Avg. reward: 1.2307692307692308\n",
      "State: [[-0.07614597 -0.3289276   0.16258941  0.10314955]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2 3 3 0]\n",
      "Reward: 1, Avg. reward: 1.2282608695652173\n",
      "State: [[-0.10902539 -0.12935317 -0.51448526  0.22753638]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0 2 0 4]\n",
      "Reward: 2, Avg. reward: 1.2365591397849462\n",
      "State: [[-0.07163747 -0.33539925 -0.38400199 -0.26102456]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0 2 1 0]\n",
      "Reward: 1, Avg. reward: 1.2340425531914894\n",
      "State: [[-0.37046215  0.11294908 -0.03923286 -0.26908491]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0 2 0 0]\n",
      "Reward: 1, Avg. reward: 1.231578947368421\n",
      "State: [[-0.15451857 -0.05236489 -0.02397721 -0.01733582]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2 0 2 1]\n",
      "Reward: 0, Avg. reward: 1.21875\n",
      "State: [[-0.20806959 -0.10542376  0.25024807  0.08777028]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0 0 2 0]\n",
      "Reward: -1, Avg. reward: 1.1958762886597938\n",
      "State: [[-0.03998985  0.22932922  0.12862794 -0.43816221]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3 0 2 1]\n",
      "Reward: 2, Avg. reward: 1.2040816326530612\n",
      "State: [[-0.10182003  0.02118275  0.10057927 -0.39190115]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2 2 2 0]\n",
      "Reward: 2, Avg. reward: 1.2121212121212122\n",
      "State: [[-0.14340845 -0.10952524 -0.34466031 -0.24098009]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 0 3 0 2]\n",
      "Reward: 1, Avg. reward: 1.21\n",
      "State: [[-0.18710445 -0.03438969 -0.07911931 -0.10143601]]\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example code, that stimulates the network 100 times with a randomly sampled action, while calculating also the average reward received\n",
    "\n",
    "total_reward = 0\n",
    "action_count = 0\n",
    "\n",
    "for _ in range(100):\n",
    "    # For simplicity, choose a random action\n",
    "    action = env.action_space.sample()\n",
    "    print(f\"Stimulate with action: {action}\")\n",
    "    \n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    action_count += 1\n",
    "\n",
    "    print(f\"Reward: {reward}, Avg. reward: {total_reward/action_count}\")\n",
    "    print(f\"State: {state}\")\n",
    "\n",
    "    # If you want a more complete plotting of each step\n",
    "    # env.render()\n",
    "\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d4ecccb-a597-4505-b3a2-6881380908e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 1.21\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average reward: {total_reward/action_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
